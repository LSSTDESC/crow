{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a72f52a-f640-4fc5-aaf9-a398edc81a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/sps/lsst/users/ebarroso/crow\")\n",
    "from crow.cluster_modules.shear_profile import *\n",
    "from crow.recipes.murata_binned_spec_z_grid_real import MurataBinnedSpecZRecipeGrid\n",
    "from crow.recipes.murata_binned_spec_z import MurataBinnedSpecZRecipe\n",
    "from crow.cluster_modules.mass_proxy import MurataBinned\n",
    "from crow.cluster_modules.kernel import SpectroscopicRedshift\n",
    "from crow.cluster_modules.purity import PurityAguena16\n",
    "from crow.cluster_modules.completeness import CompletenessAguena16\n",
    "#from firecrown.models.cluster import ClusterProperty\n",
    "from crow.properties import ClusterProperty\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from scipy.integrate import dblquad, tplquad, simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09177aa0-dd06-4bf4-b52d-c42b63e99320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyccl as ccl\n",
    "hmf = ccl.halos.MassFuncTinker08(mass_def=\"200c\")\n",
    "cosmo = ccl.Cosmology(\n",
    "    Omega_c=0.2607,      # Cold dark matter density\n",
    "    Omega_b=0.04897,     # Baryon density\n",
    "    h=0.6766,            # Hubble parameter\n",
    "    sigma8=0.8102,       # Matter fluctuation amplitude\n",
    "    n_s=0.9665,          # Spectral index\n",
    ")\n",
    "cl_delta_sigma = ClusterShearProfile(cosmo, hmf, 4.0, True)\n",
    "pivot_mass, pivot_redshift = 14.625862906, 0.6\n",
    "comp_dist = CompletenessAguena16()\n",
    "pur_dist = PurityAguena16()\n",
    "mass_distribution = MurataBinned(pivot_mass, pivot_redshift)#, pur_dist)\n",
    "redshift_distribution = SpectroscopicRedshift()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b708fef-7cdb-4239-84af-3f1520364076",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Parameters to be used in both recipes #####\n",
    "mass_points = 100\n",
    "redshift_points = 30\n",
    "log_proxy_points = 20\n",
    "sky_area = 440\n",
    "mass_interval = (12.0, 17.0)\n",
    "cluster_theory = cl_delta_sigma\n",
    "z_bin = (0.2, 0.4)\n",
    "z_points = np.linspace(z_bin[0], z_bin[1], redshift_points) \n",
    "proxy_bin = (1.0, 1.3)\n",
    "proxy_points = np.linspace(proxy_bin[0], proxy_bin[1], log_proxy_points)\n",
    "radius_center = 4.0\n",
    "#################################################\n",
    "\n",
    "recipe_integral = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution,\n",
    "        completeness=comp_dist,\n",
    "    )\n",
    "\n",
    "recipe_grid = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution,\n",
    "        completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f97ac-bcc5-4349-9bff-725fff9c068d",
   "metadata": {},
   "source": [
    "## Testing mass function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61286b9-ed09-4354-8311-f60b17e62d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 268878.88767182204, dblquad integral 268878.7658501723\n",
      "Abs error 0.12182164972182363, rel error 4.530727792939615e-07\n"
     ]
    }
   ],
   "source": [
    "hmf_grid = recipe_grid.compute_hmf_grid(z_points, sky_area)\n",
    "log_mass_grid = recipe_grid.log_mass_grid\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    \"\"\"\n",
    "    Inputs from dblquad are SCALARS:\n",
    "    1. log_mass_scalar (y-variable in dblquad)\n",
    "    2. z_scalar (x-variable in dblquad)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert scalars to single-element arrays to satisfy the methods\n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "\n",
    "    # 2. Call the methods with the correct, named arrays\n",
    "    # comoving_volume(z, sky_area)\n",
    "    vol_array = recipe_integral.cluster_theory.comoving_volume(z_array, sky_area)\n",
    "    \n",
    "    # mass_function(log_mass, z)\n",
    "    hmf_array = recipe_integral.cluster_theory.mass_function(log_mass_array, z_array)\n",
    "    \n",
    "    # 3. Return the result as a scalar float\n",
    "    return (vol_array * hmf_array)[0]\n",
    "\n",
    "\n",
    "\n",
    "integral_hmf, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "integral_over_mass = simpson(\n",
    "    y=hmf_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# The result is the final scalar integrated number count\n",
    "simpson_hmf = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ac7fe-1355-4c01-aa19-c92a322b57c0",
   "metadata": {},
   "source": [
    "## Testing mass-richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2959bb4-3215-4d63-8c05-372f1fa0c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BECAUSE MASS RICHNESS INTEGRAL HAS PURITY INSIDE, INSTANTIATE A NEW ONE FOR THIS TEST\n",
      "Simpson Integral 0.07500000000000002, dblquad integral 0.07500000000000012\n",
      "Abs error 9.71445146547012e-17, rel error 1.3322676295501878e-15\n"
     ]
    }
   ],
   "source": [
    "mass_richness_grid = recipe_grid.compute_mass_richness_grid(z_points, proxy_points)\n",
    "###################3\n",
    "print(f\"BECAUSE MASS RICHNESS INTEGRAL HAS PURITY INSIDE, INSTANTIATE A NEW ONE FOR THIS TEST\")\n",
    "mass_distribution_pure = MurataBinned(pivot_mass, pivot_redshift)\n",
    "recipe_integral_pure = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "    )\n",
    "################################\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    \"\"\"\n",
    "    Inputs from dblquad are SCALARS:\n",
    "    1. log_mass_scalar (y-variable in dblquad)\n",
    "    2. z_scalar (x-variable in dblquad)\n",
    "    \"\"\"\n",
    "    \n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "    return recipe_integral.mass_distribution.distribution(log_mass_array, z_array, proxy_bin)    \n",
    "\n",
    "z_grid_mesh, log_mass_grid_mesh = np.meshgrid(\n",
    "            z_points, log_mass_grid, indexing='ij'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "integral_mass_richness, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "\n",
    "integral_over_mass = simpson(\n",
    "    y=mass_richness_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=2\n",
    ")\n",
    "\n",
    "integral_over_proxy = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=proxy_points * np.log(10.0), \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "simpson_mass_richness = simpson(\n",
    "    y=integral_over_proxy, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_mass_richness}, dblquad integral {integral_mass_richness}\")\n",
    "print(f\"Abs error {abs(integral_mass_richness - simpson_mass_richness)}, rel error {abs(1.0 - simpson_mass_richness/integral_mass_richness)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd234884-7e95-4e76-bcd8-d75b11d67295",
   "metadata": {},
   "source": [
    "## Testing completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c1d58c-4397-435a-a5d1-686142142e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 0.6853199859674308, dblquad integral 0.6853199864484147\n",
      "Abs error 4.809839193598009e-10, rel error 7.018384762247365e-10\n"
     ]
    }
   ],
   "source": [
    "comp_grid = recipe_grid.compute_completeness_grid(z_points)\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "    return recipe_integral.completeness_distribution(log_mass_array, z_array)\n",
    "\n",
    "\n",
    "\n",
    "integral_hmf, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "integral_over_mass = simpson(\n",
    "    y=comp_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# The result is the final scalar integrated number count\n",
    "simpson_hmf = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb769e6-b65f-4dd8-b553-e05b81a2402b",
   "metadata": {},
   "source": [
    "## Testing Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccedb072-9661-49ab-ab3a-fe84e0db8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pur_grid = recipe_grid.compute_purity_grid(z_points, proxy_points)\n",
    "# def integrand(ln_proxy_scalar, z_scalar):\n",
    "#     log_proxy_scalar = ln_proxy_scalar / np.log(10.0)\n",
    "#     z_array = np.array([z_scalar])\n",
    "#     log_proxy_array = np.array([log_proxy_scalar])\n",
    "#     return recipe_integral.mass_distribution.purity.distribution(z_array, log_proxy_array)\n",
    "\n",
    "\n",
    "\n",
    "# integral_hmf, error_estimate = dblquad(\n",
    "#     func=integrand, \n",
    "#     a=z_bin[0],       # lower limit for z (x-axis)\n",
    "#     b=z_bin[1],       # upper limit for z (x-axis)\n",
    "#     gfun=lambda x: proxy_bin[0]  * np.log(10.0), # lower limit for log_mass (y-axis)\n",
    "#     hfun=lambda x: proxy_bin[1] * np.log(10.0), # upper limit for log_mass (y-axis)\n",
    "# )\n",
    "# integral_over_proxy = simpson(\n",
    "#     y=pur_grid, \n",
    "#     x=proxy_points, \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# # The result is the final scalar integrated number count\n",
    "# simpson_hmf = simpson(\n",
    "#     y=integral_over_proxy * np.log(10.0), \n",
    "#     x=z_points, \n",
    "#     axis=0\n",
    "# )\n",
    "\n",
    "# print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "# print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608587d5-2610-4a02-9005-73f2ae9fac53",
   "metadata": {},
   "source": [
    "## Testing Shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505b8dfa-d289-45d9-9ea7-1058b7d51e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 97566729539515.73, dblquad integral 97566654129403.34\n",
      "Abs error 75410112.390625, rel error 7.729086650698491e-07\n"
     ]
    }
   ],
   "source": [
    "shear_grid = recipe_grid.compute_shear_grid(z_points, radius_center)\n",
    "log_mass_grid = recipe_grid.log_mass_grid\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    \"\"\"\n",
    "    Inputs from dblquad are SCALARS:\n",
    "    1. log_mass_scalar (y-variable in dblquad)\n",
    "    2. z_scalar (x-variable in dblquad)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert scalars to single-element arrays to satisfy the methods\n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "    shear = recipe_integral.cluster_theory.compute_shear_profile(log_mass_array, z_array, radius_center = radius_center)\n",
    "    \n",
    "    # 3. Return the result as a scalar float\n",
    "    return shear[0]\n",
    "\n",
    "\n",
    "\n",
    "integral_hmf, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "integral_over_mass = simpson(\n",
    "    y=shear_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# The result is the final scalar integrated number count\n",
    "simpson_hmf = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f04d1-09ec-46c7-acdb-688f6636b22a",
   "metadata": {},
   "source": [
    "## Testing Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50694f5b-f501-4ab1-86f2-11c09b6faf9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, 0.4) (1.0, 1.3)\n",
      "Simpson Integral 465.89130908891366, dblquad integral 465.89348909430385\n",
      "Abs error 0.002180005390187034, rel error 4.679192650680619e-06\n",
      "First eval took: 0.007207155227661133, second eval took: 0.0014400482177734375, integral took: 0.07780647277832031\n",
      "After reset: 0.0068874359130859375\n",
      " Counts 1, 2 ,3: (np.float64(465.89130908891366), np.float64(465.89130908891366), np.float64(465.89130908891366))\n"
     ]
    }
   ],
   "source": [
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area)\n",
    "t2 = time.time()\n",
    "print(z_bin, proxy_bin)\n",
    "counts_integral = recipe_integral_pure.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Counts 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a9bca-43cd-4a2a-b85c-27f53082d40f",
   "metadata": {},
   "source": [
    "## Testing Shear Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbafeee-635b-4770-8f08-96bfeffec78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 3674727743264800.0, dblquad integral 3832214530946015.0\n",
      "Abs error 157486787681215.0, rel error 0.041095504025015495\n",
      "First eval took: 1.305562973022461, second eval took: 0.0015537738800048828, integral took: 0.5741713047027588\n",
      "After reset: 1.3940379619598389\n",
      " Counts 1, 2 ,3: (np.float64(3674727743264800.0), np.float64(3674727743264800.0), np.float64(3674727743264800.0))\n"
     ]
    }
   ],
   "source": [
    "average_on = ClusterProperty.NONE\n",
    "average_on |= ClusterProperty.DELTASIGMA\n",
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center,sky_area, average_on)\n",
    "t2 = time.time()\n",
    "counts_integral = recipe_integral_pure.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center, sky_area,average_on)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center, sky_area,average_on)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center, sky_area,average_on)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Counts 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d2461-258a-4f22-a545-2a189a16e146",
   "metadata": {},
   "source": [
    "## Test speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d082c4-49b9-4a47-bafd-aaa784940307",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_distribution_pure = MurataBinned(pivot_mass, pivot_redshift)\n",
    "\n",
    "\n",
    "##### Parameters to be used in both recipes #####\n",
    "mass_points = 101\n",
    "redshift_points = 40\n",
    "log_proxy_points = 40\n",
    "sky_area = 440\n",
    "mass_interval = (12.0, 17.0)\n",
    "cluster_theory = cl_delta_sigma\n",
    "z_bin = (0.2, 0.4)\n",
    "z_points = np.linspace(z_bin[0], z_bin[1], redshift_points) \n",
    "proxy_bin = (1.0, 1.3)\n",
    "proxy_points = np.linspace(proxy_bin[0], proxy_bin[1], log_proxy_points)\n",
    "radius_center = 4.0\n",
    "average_on_counts = ClusterProperty.NONE\n",
    "average_on_shear = ClusterProperty.NONE\n",
    "average_on_shear |= ClusterProperty.DELTASIGMA\n",
    "#################################################\n",
    "\n",
    "recipe_integral_speed = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "    )\n",
    "\n",
    "recipe_grid_speed = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    "    )\n",
    "recipe_grid_speed.reset_grids_cache()\n",
    "counts_grid = recipe_grid_speed.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area,average_on_counts)\n",
    "counts_integral = recipe_integral_speed.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area, average_on_counts)\n",
    "\n",
    "counts_grid = recipe_grid_speed.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center,sky_area, average_on_shear)\n",
    "t2 = time.time()\n",
    "counts_integral = recipe_integral_speed.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center, sky_area,average_on_shear)\n",
    "t21 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51bab1ac-1e14-4b76-be56-6e98da5cd035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- One-shot counts ---\n",
      "Grid time:    0.2770 s\n",
      "Integral time: 0.0027 s\n",
      "\n",
      "--- One-shot shear ---\n",
      "Grid time:    0.9574 s\n",
      "Integral time: 0.5117 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Your parameters\n",
    "mass_distribution_pure = MurataBinned(pivot_mass, pivot_redshift)\n",
    "\n",
    "mass_points = 101\n",
    "redshift_points = 20\n",
    "log_proxy_points = 20\n",
    "sky_area = 440\n",
    "mass_interval = (12.0, 17.0)\n",
    "z_bin = (0.2, 0.4)\n",
    "proxy_bin = (1.0, 1.3)\n",
    "radius_center = 4.0\n",
    "\n",
    "average_on_counts = ClusterProperty.NONE\n",
    "average_on_shear  = ClusterProperty.DELTASIGMA\n",
    "\n",
    "# Recipes\n",
    "recipe_integral_speed = MurataBinnedSpecZRecipe(\n",
    "    mass_interval=mass_interval,\n",
    "    cluster_theory=cl_delta_sigma,\n",
    "    redshift_distribution=redshift_distribution,\n",
    "    mass_distribution=mass_distribution_pure,\n",
    "    completeness=comp_dist,\n",
    ")\n",
    "\n",
    "recipe_grid_speed = MurataBinnedSpecZRecipeGrid(\n",
    "    mass_interval=mass_interval,\n",
    "    cluster_theory=cl_delta_sigma,\n",
    "    redshift_distribution=redshift_distribution,\n",
    "    mass_distribution=mass_distribution_pure,\n",
    "    completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    ")\n",
    "\n",
    "# ---- One-shot timing: counts ----\n",
    "recipe_grid_speed.reset_grids_cache()\n",
    "\n",
    "t0 = time.time()\n",
    "counts_grid = recipe_grid_speed.evaluate_theory_prediction_counts(\n",
    "    z_bin, proxy_bin, sky_area, average_on_counts\n",
    ")\n",
    "t1 = time.time()\n",
    "\n",
    "counts_integral = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "    z_bin, proxy_bin, sky_area, average_on_counts\n",
    ")\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"\\n--- One-shot counts ---\")\n",
    "print(\"Grid time:    %.4f s\" % (t1 - t0))\n",
    "print(\"Integral time: %.4f s\" % (t2 - t1))\n",
    "\n",
    "\n",
    "# ---- One-shot timing: shear ----\n",
    "t0 = time.time()\n",
    "shear_grid = recipe_grid_speed.evaluate_theory_prediction_shear_profile(\n",
    "    z_bin, proxy_bin, radius_center, sky_area, average_on_shear\n",
    ")\n",
    "t1 = time.time()\n",
    "\n",
    "shear_integral = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "    z_bin, proxy_bin, radius_center, sky_area, average_on_shear\n",
    ")\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"\\n--- One-shot shear ---\")\n",
    "print(\"Grid time:    %.4f s\" % (t1 - t0))\n",
    "print(\"Integral time: %.4f s\" % (t2 - t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01bb54c3-0ea1-4376-a7df-aa336ff5344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOTAL GRID TIME = 14.76 s\n",
      "TOTAL INTEGRAL TIME = 29.54 s\n",
      "\n",
      "--- RESULTS COMPARISON ---\n",
      "Total number of bins computed: 80\n",
      "RMS Relative Diff (Counts): 4.3241e-06\n",
      "RMS Relative Diff (Shear):  2.6710e-02\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "richness_bins = [(0.3,0.4), (0.4,0.6), (0.6,0.8), (0.8,1.0)]   # example\n",
    "proxy_bins    = [(1.0,1.1), (1.1,1.2), (1.2,1.3), (1.3,1.4), (1.4,1.5)]\n",
    "radii         = np.linspace(1.0, 10.0, 4)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Total GRID computation time\n",
    "# ----------------------------------------------\n",
    "recipe_grid_speed.reset_grids_cache()\n",
    "counts_grid_arr = []\n",
    "shear_grid_arr = []\n",
    "tg0 = time.time()\n",
    "for rbin in richness_bins:\n",
    "    for pbin in proxy_bins:\n",
    "        for R in radii:\n",
    "            counts_grid_arr.append(recipe_grid_speed.evaluate_theory_prediction_counts(rbin, pbin, sky_area, average_on_counts))\n",
    "            shear_grid_arr.append(recipe_grid_speed.evaluate_theory_prediction_shear_profile(rbin, pbin, R, sky_area, average_on_shear))\n",
    "tg1 = time.time()\n",
    "print(\"\\nTOTAL GRID TIME = %.2f s\" % (tg1 - tg0))\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Total INTEGRAL computation time\n",
    "# ----------------------------------------------\n",
    "counts_int_arr = []\n",
    "shear_int_arr = []\n",
    "ti0 = time.time()\n",
    "for rbin in richness_bins:\n",
    "    for pbin in proxy_bins:\n",
    "        for R in radii:\n",
    "            counts_int_arr.append(recipe_integral_speed.evaluate_theory_prediction_counts(rbin, pbin, sky_area, average_on_counts))\n",
    "            shear_int_arr.append(recipe_integral_speed.evaluate_theory_prediction_shear_profile(rbin, pbin, R, sky_area, average_on_shear))\n",
    "ti1 = time.time()\n",
    "print(\"TOTAL INTEGRAL TIME = %.2f s\" % (ti1 - ti0))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Comparison of Results\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Convert lists to NumPy arrays for easy calculation\n",
    "counts_grid = np.array(counts_grid_arr)\n",
    "counts_int = np.array(counts_int_arr)\n",
    "shear_grid = np.array(shear_grid_arr)\n",
    "shear_int = np.array(shear_int_arr)\n",
    "\n",
    "counts_diff = np.where(\n",
    "    counts_int != 0.0, \n",
    "    np.abs(counts_grid - counts_int) / np.abs(counts_int), \n",
    "    0.0\n",
    ")\n",
    "rms_counts_diff = np.sqrt(np.mean(counts_diff**2))\n",
    "\n",
    "shear_diff = np.where(\n",
    "    shear_int != 0.0, \n",
    "    np.abs(shear_grid - shear_int) / np.abs(shear_int), \n",
    "    0.0\n",
    ")\n",
    "rms_shear_diff = np.sqrt(np.mean(shear_diff**2))\n",
    "\n",
    "# Final Comparison Printout\n",
    "print(\"\\n--- RESULTS COMPARISON ---\")\n",
    "print(\"Total number of bins computed: %d\" % len(counts_grid))\n",
    "print(\"RMS Relative Diff (Counts): %.4e\" % rms_counts_diff)\n",
    "print(\"RMS Relative Diff (Shear):  %.4e\" % rms_shear_diff)\n",
    "print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58905869-59a8-4f10-a321-9a4f6ffe87b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterProperty.DELTASIGMA\n"
     ]
    }
   ],
   "source": [
    "print(average_on_shear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80383885-0945-4e1c-bf2e-ed64072d9130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BEGIN ACCURACY SWEEP WITH COUNTS =====\n",
      "\n",
      "Test bin:\n",
      "  z = (0.200, 0.400)\n",
      "  proxy = (1.000, 1.300)\n",
      "  R = 4.000\n",
      "\n",
      "---- Sweep log_proxy_points ----\n",
      "\n",
      "Trying log_proxy_points = 2\n",
      "  shear diff  = 0.032592\n",
      "  counts diff = 0.121889\n",
      "\n",
      "Trying log_proxy_points = 5\n",
      "  shear diff  = 0.041111\n",
      "  counts diff = 0.000032\n",
      "\n",
      "Trying log_proxy_points = 10\n",
      "  shear diff  = 0.041094\n",
      "  counts diff = 0.000012\n",
      "\n",
      "Trying log_proxy_points = 20\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_proxy_points = 30\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_proxy_points = 40\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_proxy_points = 60\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_proxy_points = 80\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_proxy_points = 120\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_proxy_points = 160\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "---- Sweep redshift_points ----\n",
      "\n",
      "Trying redshift_points = 2\n",
      "  shear diff  = 0.069252\n",
      "  counts diff = 0.035580\n",
      "\n",
      "Trying redshift_points = 5\n",
      "  shear diff  = 0.041092\n",
      "  counts diff = 0.000003\n",
      "\n",
      "Trying redshift_points = 10\n",
      "  shear diff  = 0.041091\n",
      "  counts diff = 0.000001\n",
      "\n",
      "Trying redshift_points = 20\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying redshift_points = 30\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying redshift_points = 40\n",
      "  shear diff  = 0.041095\n",
      "  counts diff = 0.000004\n",
      "\n",
      "---- Sweep log_mass_points ----\n",
      "\n",
      "Trying log_mass_points = 5\n",
      "  shear diff  = 0.094825\n",
      "  counts diff = 0.229872\n",
      "\n",
      "Trying log_mass_points = 10\n",
      "  shear diff  = 0.258589\n",
      "  counts diff = 0.168360\n",
      "\n",
      "Trying log_mass_points = 20\n",
      "  shear diff  = 0.002523\n",
      "  counts diff = 0.008279\n",
      "\n",
      "Trying log_mass_points = 40\n",
      "  shear diff  = 0.041051\n",
      "  counts diff = 0.000101\n",
      "\n",
      "Trying log_mass_points = 60\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_mass_points = 80\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "Trying log_mass_points = 120\n",
      "  shear diff  = 0.041096\n",
      "  counts diff = 0.000005\n",
      "\n",
      "===== END ACCURACY SWEEP WITH COUNTS =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def frac_diff(a, b):\n",
    "    return np.abs(a - b) / (np.abs(b) + 1e-12)\n",
    "\n",
    "\n",
    "print(\"\\n===== BEGIN ACCURACY SWEEP WITH COUNTS =====\\n\")\n",
    "\n",
    "# --- ranges to test ---\n",
    "proxy_sweep    = [2, 5, 10, 20, 30, 40, 60, 80, 120, 160]\n",
    "z_sweep        = [2, 5, 10, 20, 30, 40]\n",
    "mass_sweep     = [5, 10, 20, 40, 60, 80, 120]\n",
    "\n",
    "# --- fixed test bin ---\n",
    "z_lo, z_hi = z_bin\n",
    "proxy_lo, proxy_hi = proxy_bin\n",
    "R = radius_center\n",
    "\n",
    "print(\"Test bin:\")\n",
    "print(\"  z = (%.3f, %.3f)\" % z_bin)\n",
    "print(\"  proxy = (%.3f, %.3f)\" % proxy_bin)\n",
    "print(\"  R = %.3f\" % R)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1) PROXY SWEEP\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n---- Sweep log_proxy_points ----\")\n",
    "\n",
    "for pts in proxy_sweep:\n",
    "    print(f\"\\nTrying log_proxy_points = {pts}\")\n",
    "\n",
    "    recipe_grid_speed_pts = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_delta_sigma,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "        log_proxy_points=pts,\n",
    "        redshift_points=redshift_points,\n",
    "        log_mass_points=mass_points,\n",
    "    )\n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    # Shear evaluation\n",
    "    val_shear = recipe_grid_speed_pts.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    \n",
    "    # Counts evaluation\n",
    "    counts_val = recipe_grid_speed_pts.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    # Reference shear\n",
    "    ref_shear = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    \n",
    "    # Reference counts\n",
    "    ref_counts = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    diff_shear  = float(frac_diff(val_shear, ref_shear))\n",
    "    diff_counts = float(frac_diff(counts_val, ref_counts))\n",
    "\n",
    "    print(\"  shear diff  = %.6f\" % diff_shear)\n",
    "    print(\"  counts diff = %.6f\" % diff_counts)\n",
    "\n",
    "    if diff_shear < 0.01 and diff_counts < 0.01:\n",
    "        print(\"  → Achieved ≤1% accuracy at log_proxy_points =\", pts)\n",
    "        break\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) REDSHIFT SWEEP\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n---- Sweep redshift_points ----\")\n",
    "\n",
    "for pts in z_sweep:\n",
    "    print(f\"\\nTrying redshift_points = {pts}\")\n",
    "\n",
    "    recipe_grid_speed_pts = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_delta_sigma,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "        log_proxy_points=log_proxy_points,\n",
    "        redshift_points=pts,\n",
    "        log_mass_points=mass_points,\n",
    "    )\n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    val_shear = recipe_grid_speed_pts.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    counts_val = recipe_grid_speed_pts.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "\n",
    "    ref_shear = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    ref_counts = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    diff_shear  = float(frac_diff(val_shear, ref_shear))\n",
    "    diff_counts = float(frac_diff(counts_val, ref_counts))\n",
    "    \n",
    "    print(\"  shear diff  = %.6f\" % diff_shear)\n",
    "    print(\"  counts diff = %.6f\" % diff_counts)\n",
    "\n",
    "    if diff_shear < 0.01 and diff_counts < 0.01:\n",
    "        print(\"  → Achieved ≤1% accuracy at redshift_points =\", pts)\n",
    "        break\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) MASS SWEEP\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n---- Sweep log_mass_points ----\")\n",
    "\n",
    "for pts in mass_sweep:\n",
    "    print(f\"\\nTrying log_mass_points = {pts}\")\n",
    "\n",
    "    recipe_grid_speed_pts = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_delta_sigma,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "        log_proxy_points=log_proxy_points,\n",
    "        redshift_points=redshift_points,\n",
    "        log_mass_points=pts,\n",
    "    )\n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    val_shear = recipe_grid_speed_pts.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    counts_val = recipe_grid_speed_pts.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin,  sky_area\n",
    "    )\n",
    "\n",
    "    ref_shear = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    ref_counts = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    diff_shear  = float(frac_diff(val_shear, ref_shear))\n",
    "    diff_counts = float(frac_diff(counts_val, ref_counts))\n",
    "    \n",
    "    print(\"  shear diff  = %.6f\" % diff_shear)\n",
    "    print(\"  counts diff = %.6f\" % diff_counts)\n",
    "\n",
    "    # Optional early break if both ≤1%\n",
    "    # if diff_shear < 0.01 and diff_counts < 0.01:\n",
    "    #     print(\"  → Achieved ≤1% accuracy at log_mass_points =\", pts)\n",
    "    #     break\n",
    "\n",
    "\n",
    "print(\"\\n===== END ACCURACY SWEEP WITH COUNTS =====\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244aaf96-29eb-476c-b821-e06bccc2a954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.    3.25  5.5   7.75 10.  ]\n"
     ]
    }
   ],
   "source": [
    "print(np.linspace(1,10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac3e65-7df4-416b-bd47-1c7cdd6b49b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (firecrown20.0)",
   "language": "python",
   "name": "firecrown_20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
