{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a72f52a-f640-4fc5-aaf9-a398edc81a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/sps/lsst/users/ebarroso/crow\")\n",
    "from crow.cluster_modules.shear_profile import *\n",
    "from crow.recipes.murata_binned_spec_z_grid_real import MurataBinnedSpecZRecipeGrid\n",
    "from crow.recipes.murata_binned_spec_z import MurataBinnedSpecZRecipe\n",
    "from crow.cluster_modules.mass_proxy import MurataBinned\n",
    "from crow.cluster_modules.kernel import SpectroscopicRedshift\n",
    "from crow.cluster_modules.purity import PurityAguena16\n",
    "from crow.cluster_modules.completeness import CompletenessAguena16\n",
    "#from firecrown.models.cluster import ClusterProperty\n",
    "from crow.properties import ClusterProperty\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from scipy.integrate import dblquad, tplquad, simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09177aa0-dd06-4bf4-b52d-c42b63e99320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyccl as ccl\n",
    "hmf = ccl.halos.MassFuncTinker08(mass_def=\"200c\")\n",
    "cosmo = ccl.Cosmology(\n",
    "    Omega_c=0.2607,      # Cold dark matter density\n",
    "    Omega_b=0.04897,     # Baryon density\n",
    "    h=0.6766,            # Hubble parameter\n",
    "    sigma8=0.8102,       # Matter fluctuation amplitude\n",
    "    n_s=0.9665,          # Spectral index\n",
    ")\n",
    "cl_delta_sigma = ClusterShearProfile(cosmo, hmf, 4.0, True)\n",
    "pivot_mass, pivot_redshift = 14.625862906, 0.6\n",
    "comp_dist = CompletenessAguena16()\n",
    "pur_dist = PurityAguena16()\n",
    "mass_distribution = MurataBinned(pivot_mass, pivot_redshift)#, pur_dist)\n",
    "redshift_distribution = SpectroscopicRedshift()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b708fef-7cdb-4239-84af-3f1520364076",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Parameters to be used in both recipes #####\n",
    "mass_points = 30\n",
    "redshift_points = 10\n",
    "log_proxy_points = 10\n",
    "sky_area = 440\n",
    "mass_interval = (12.5, 15.0)\n",
    "cluster_theory = cl_delta_sigma\n",
    "z_bin = (0.2, 0.4)\n",
    "z_points = np.linspace(z_bin[0], z_bin[1], redshift_points) \n",
    "proxy_bin = (1.0, 1.3)\n",
    "proxy_points = np.linspace(proxy_bin[0], proxy_bin[1], log_proxy_points)\n",
    "radius_center = 4.0\n",
    "#################################################\n",
    "\n",
    "recipe_integral = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution,\n",
    "        #completeness=comp_dist,\n",
    "    )\n",
    "\n",
    "recipe_grid = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution,\n",
    "        #completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22c7b083-c3ca-4f75-9726-02777bb5bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(recipe_integral.completeness_distribution(np.array([mass_interval[0]]),np.array([z_bin[0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f97ac-bcc5-4349-9bff-725fff9c068d",
   "metadata": {},
   "source": [
    "## Testing mass function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a61286b9-ed09-4354-8311-f60b17e62d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 87221.31147840535, dblquad integral 87220.6489541402\n",
      "Abs error 0.6625242651498411, rel error 7.595956612371779e-06\n"
     ]
    }
   ],
   "source": [
    "hmf_grid = recipe_grid.get_hmf_grid(z_points, sky_area, z_bin)\n",
    "log_mass_grid = recipe_grid.log_mass_grid\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    \"\"\"\n",
    "    Inputs from dblquad are SCALARS:\n",
    "    1. log_mass_scalar (y-variable in dblquad)\n",
    "    2. z_scalar (x-variable in dblquad)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert scalars to single-element arrays to satisfy the methods\n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "\n",
    "    # 2. Call the methods with the correct, named arrays\n",
    "    # comoving_volume(z, sky_area)\n",
    "    vol_array = recipe_integral.cluster_theory.comoving_volume(z_array, sky_area)\n",
    "    \n",
    "    # mass_function(log_mass, z)\n",
    "    hmf_array = recipe_integral.cluster_theory.mass_function(log_mass_array, z_array)\n",
    "    \n",
    "    # 3. Return the result as a scalar float\n",
    "    return (vol_array * hmf_array)[0]\n",
    "\n",
    "\n",
    "\n",
    "integral_hmf, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "integral_over_mass = simpson(\n",
    "    y=hmf_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# The result is the final scalar integrated number count\n",
    "simpson_hmf = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ac7fe-1355-4c01-aa19-c92a322b57c0",
   "metadata": {},
   "source": [
    "## Testing mass-richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2959bb4-3215-4d63-8c05-372f1fa0c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BECAUSE MASS RICHNESS INTEGRAL HAS PURITY INSIDE, INSTANTIATE A NEW ONE FOR THIS TEST\n",
      "Simpson Integral 0.07492096465752202, dblquad integral 0.0749396525986431\n",
      "Abs error 1.868794112108718e-05, rel error 0.0002493732019438477\n"
     ]
    }
   ],
   "source": [
    "mass_richness_grid = recipe_grid.get_mass_richness_grid(z_points, proxy_points, (z_bin, proxy_bin))\n",
    "###################3\n",
    "print(f\"BECAUSE MASS RICHNESS INTEGRAL HAS PURITY INSIDE, INSTANTIATE A NEW ONE FOR THIS TEST\")\n",
    "mass_distribution_pure = MurataBinned(pivot_mass, pivot_redshift)\n",
    "recipe_integral_pure = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        completeness=comp_dist,\n",
    "    )\n",
    "################################\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    \"\"\"\n",
    "    Inputs from dblquad are SCALARS:\n",
    "    1. log_mass_scalar (y-variable in dblquad)\n",
    "    2. z_scalar (x-variable in dblquad)\n",
    "    \"\"\"\n",
    "    \n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "    return recipe_integral.mass_distribution.distribution(log_mass_array, z_array, proxy_bin)    \n",
    "\n",
    "z_grid_mesh, log_mass_grid_mesh = np.meshgrid(\n",
    "            z_points, log_mass_grid, indexing='ij'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "integral_mass_richness, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "\n",
    "integral_over_mass = simpson(\n",
    "    y=mass_richness_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=2\n",
    ")\n",
    "\n",
    "integral_over_proxy = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=proxy_points * np.log(10.0), \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "simpson_mass_richness = simpson(\n",
    "    y=integral_over_proxy, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_mass_richness}, dblquad integral {integral_mass_richness}\")\n",
    "print(f\"Abs error {abs(integral_mass_richness - simpson_mass_richness)}, rel error {abs(1.0 - simpson_mass_richness/integral_mass_richness)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd234884-7e95-4e76-bcd8-d75b11d67295",
   "metadata": {},
   "source": [
    "## Testing completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c1d58c-4397-435a-a5d1-686142142e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 0.5, dblquad integral 0.5\n",
      "Abs error 0.0, rel error 0.0\n"
     ]
    }
   ],
   "source": [
    "comp_grid = recipe_grid.get_completeness_grid(z_points, z_bin)\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "    return recipe_integral.completeness_distribution(log_mass_array, z_array)\n",
    "\n",
    "\n",
    "\n",
    "integral_hmf, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "integral_over_mass = simpson(\n",
    "    y=comp_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# The result is the final scalar integrated number count\n",
    "simpson_hmf = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb769e6-b65f-4dd8-b553-e05b81a2402b",
   "metadata": {},
   "source": [
    "## Testing Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccedb072-9661-49ab-ab3a-fe84e0db8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pur_grid = recipe_grid.compute_purity_grid(z_points, proxy_points)\n",
    "# def integrand(ln_proxy_scalar, z_scalar):\n",
    "#     log_proxy_scalar = ln_proxy_scalar / np.log(10.0)\n",
    "#     z_array = np.array([z_scalar])\n",
    "#     log_proxy_array = np.array([log_proxy_scalar])\n",
    "#     return recipe_integral.mass_distribution.purity.distribution(z_array, log_proxy_array)\n",
    "\n",
    "\n",
    "\n",
    "# integral_hmf, error_estimate = dblquad(\n",
    "#     func=integrand, \n",
    "#     a=z_bin[0],       # lower limit for z (x-axis)\n",
    "#     b=z_bin[1],       # upper limit for z (x-axis)\n",
    "#     gfun=lambda x: proxy_bin[0]  * np.log(10.0), # lower limit for log_mass (y-axis)\n",
    "#     hfun=lambda x: proxy_bin[1] * np.log(10.0), # upper limit for log_mass (y-axis)\n",
    "# )\n",
    "# integral_over_proxy = simpson(\n",
    "#     y=pur_grid, \n",
    "#     x=proxy_points, \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# # The result is the final scalar integrated number count\n",
    "# simpson_hmf = simpson(\n",
    "#     y=integral_over_proxy * np.log(10.0), \n",
    "#     x=z_points, \n",
    "#     axis=0\n",
    "# )\n",
    "\n",
    "# print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "# print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608587d5-2610-4a02-9005-73f2ae9fac53",
   "metadata": {},
   "source": [
    "## Testing Shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505b8dfa-d289-45d9-9ea7-1058b7d51e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 3107547234842.1655, dblquad integral 3107478462523.7495\n",
      "Abs error 68772318.41601562, rel error 2.2131229305610844e-05\n"
     ]
    }
   ],
   "source": [
    "shear_grid = recipe_grid.get_shear_grid(z_points, radius_center, z_bin)\n",
    "log_mass_grid = recipe_grid.log_mass_grid\n",
    "def integrand(log_mass_scalar, z_scalar):\n",
    "    \"\"\"\n",
    "    Inputs from dblquad are SCALARS:\n",
    "    1. log_mass_scalar (y-variable in dblquad)\n",
    "    2. z_scalar (x-variable in dblquad)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert scalars to single-element arrays to satisfy the methods\n",
    "    z_array = np.array([z_scalar])\n",
    "    log_mass_array = np.array([log_mass_scalar])\n",
    "    shear = recipe_integral.cluster_theory.compute_shear_profile(log_mass_array, z_array, radius_center = radius_center)\n",
    "    \n",
    "    # 3. Return the result as a scalar float\n",
    "    return shear[0]\n",
    "\n",
    "\n",
    "\n",
    "integral_hmf, error_estimate = dblquad(\n",
    "    func=integrand, \n",
    "    a=z_bin[0],       # lower limit for z (x-axis)\n",
    "    b=z_bin[1],       # upper limit for z (x-axis)\n",
    "    gfun=lambda x: mass_interval[0], # lower limit for log_mass (y-axis)\n",
    "    hfun=lambda x: mass_interval[1]  # upper limit for log_mass (y-axis)\n",
    ")\n",
    "integral_over_mass = simpson(\n",
    "    y=shear_grid, \n",
    "    x=log_mass_grid, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step B: Integrate over the redshift dimension (axis=0 of the new array)\n",
    "# The result is the final scalar integrated number count\n",
    "simpson_hmf = simpson(\n",
    "    y=integral_over_mass, \n",
    "    x=z_points, \n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"Simpson Integral {simpson_hmf}, dblquad integral {integral_hmf}\")\n",
    "print(f\"Abs error {abs(integral_hmf - simpson_hmf)}, rel error {abs(1.0 - simpson_hmf/integral_hmf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f04d1-09ec-46c7-acdb-688f6636b22a",
   "metadata": {},
   "source": [
    "## Testing Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50694f5b-f501-4ab1-86f2-11c09b6faf9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, 0.4) (1.0, 1.3)\n",
      "Simpson Integral 492.44829165465876, dblquad integral 492.4758087098605\n",
      "Abs error 0.027517055201712992, rel error 5.587493784475761e-05\n",
      "First eval took: 0.002029895782470703, second eval took: 0.0006742477416992188, integral took: 0.002042055130004883\n",
      "After reset: 0.0011742115020751953\n",
      " Counts 1, 2 ,3: (np.float64(492.44829165465876), np.float64(492.44829165465876), np.float64(492.44829165465876))\n"
     ]
    }
   ],
   "source": [
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area)\n",
    "t2 = time.time()\n",
    "print(z_bin, proxy_bin)\n",
    "counts_integral = recipe_integral.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Counts 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a9bca-43cd-4a2a-b85c-27f53082d40f",
   "metadata": {},
   "source": [
    "## Testing DeltaSigma Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbbafeee-635b-4770-8f08-96bfeffec78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 3831544942570779.0, dblquad integral 3831984682268562.0\n",
      "Abs error 439739697783.0, rel error 0.00011475507713221145\n",
      "First eval took: 0.13671040534973145, second eval took: 0.0007364749908447266, integral took: 0.14258861541748047\n",
      "After reset: 0.1403367519378662\n",
      " Counts 1, 2 ,3: (np.float64(3831544942570779.0), np.float64(3831544942570779.0), np.float64(3831544942570779.0))\n"
     ]
    }
   ],
   "source": [
    "average_on = ClusterProperty.NONE\n",
    "average_on |= ClusterProperty.DELTASIGMA\n",
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center,sky_area=sky_area, average_on=average_on)\n",
    "t2 = time.time()\n",
    "counts_integral = recipe_integral.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center, sky_area=sky_area,average_on=average_on)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center, sky_area=sky_area,average_on=average_on)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center, sky_area=sky_area,average_on=average_on)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Counts 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c38c6-b639-45ca-989e-33b1033fc1d7",
   "metadata": {},
   "source": [
    "## Testing Reduced Shear Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d1b2e7-5286-4256-a06e-19d219db6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_reduced_shear = ClusterShearProfile(cosmo, hmf, 4.0, False, True)\n",
    "cl_reduced_shear.set_beta_parameters(10)\n",
    "cl_reduced_shear.set_beta_s_interp(1.1, 1.3)\n",
    "\n",
    "recipe_integral_reduced = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_reduced_shear,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution,\n",
    "        #completeness=comp_dist,\n",
    "    )\n",
    "\n",
    "recipe_grid_reduced = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_reduced_shear,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution,\n",
    "        #completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1475ea55-2c46-4874-b8d1-651f92eb6b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson Integral 1.2280211540730646, dblquad integral 1.360873557658125\n",
      "Abs error 0.13285240358506045, rel error 0.09762288556306509\n",
      "First eval took: 0.2534449100494385, second eval took: 0.0006926059722900391, integral took: 0.32747983932495117\n",
      "After reset: 0.0006835460662841797\n",
      " Values 1, 2 ,3: (np.float64(1.2280211540730646), np.float64(1.2280211540730646), np.float64(1.2280211540730646))\n"
     ]
    }
   ],
   "source": [
    "average_on = ClusterProperty.NONE\n",
    "average_on |= ClusterProperty.DELTASIGMA\n",
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid_reduced.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center,sky_area=sky_area, average_on=average_on)\n",
    "t2 = time.time()\n",
    "counts_integral = recipe_integral_reduced.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center, sky_area=sky_area,average_on=average_on)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid_reduced.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center, sky_area=sky_area,average_on=average_on)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid_reduced.evaluate_theory_prediction_shear_profile(z_edges=z_bin, mass_proxy_edges=proxy_bin, radius_center=radius_center, sky_area=sky_area,average_on=average_on)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Values 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0614340-8f43-4971-bf58-ba8268f4bff2",
   "metadata": {},
   "source": [
    "## Testing Mean Log Mass Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19680b81-53a3-4a3c-b0cc-af012e62b7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, 0.4) (1.0, 1.3)\n",
      "Simpson Integral 7019.099215264838, dblquad integral 7019.501486555358\n",
      "Abs error 0.40227129051982047, rel error 5.7307672245765495e-05\n",
      "First eval took: 0.002022981643676758, second eval took: 0.0006885528564453125, integral took: 0.002102375030517578\n",
      "After reset: 0.0012462139129638672\n",
      " Counts 1, 2 ,3: (np.float64(7019.099215264838), np.float64(7019.099215264838), np.float64(7019.099215264838))\n"
     ]
    }
   ],
   "source": [
    "average_on_mass = ClusterProperty.NONE\n",
    "average_on_mass |= ClusterProperty.MASS\n",
    "\n",
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t2 = time.time()\n",
    "print(z_bin, proxy_bin)\n",
    "counts_integral = recipe_integral.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Counts 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb32809-467e-4eec-ae04-d58c6b52a284",
   "metadata": {},
   "source": [
    "## Testing Mean redshift Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48013b86-2d4a-49bc-94e8-a04f03e03c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, 0.4) (1.0, 1.3)\n",
      "Simpson Integral 153.81441380278108, dblquad integral 153.83237337163465\n",
      "Abs error 0.017959568853569863, rel error 0.00011674765499580797\n",
      "First eval took: 0.002019166946411133, second eval took: 0.0006821155548095703, integral took: 0.001760244369506836\n",
      "After reset: 0.0011944770812988281\n",
      " Counts 1, 2 ,3: (np.float64(153.81441380278108), np.float64(153.81441380278108), np.float64(153.81441380278108))\n"
     ]
    }
   ],
   "source": [
    "average_on_mass = ClusterProperty.NONE\n",
    "average_on_mass |= ClusterProperty.REDSHIFT\n",
    "\n",
    "recipe_grid.reset_grids_cache()\n",
    "t1 = time.time()\n",
    "counts_grid = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t2 = time.time()\n",
    "print(z_bin, proxy_bin)\n",
    "counts_integral = recipe_integral.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t21 = time.time()\n",
    "t3 = time.time()\n",
    "counts_grid_2 = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t4 = time.time()\n",
    "recipe_grid.reset_grids_cache()\n",
    "t5 = time.time()\n",
    "counts_grid_3 = recipe_grid.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area, average_on_mass)\n",
    "t6 = time.time()\n",
    "print(f\"Simpson Integral {counts_grid}, dblquad integral {counts_integral}\")\n",
    "print(f\"Abs error {abs(counts_integral - counts_grid)}, rel error {abs(1.0 - counts_grid/counts_integral)}\")\n",
    "print(f\"First eval took: {t2-t1}, second eval took: {t4-t3}, integral took: {t21-t2}\")\n",
    "print(f\"After reset: {t6-t5}\")\n",
    "print(f\" Counts 1, 2 ,3: {counts_grid, counts_grid_2, counts_grid_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d2461-258a-4f22-a545-2a189a16e146",
   "metadata": {},
   "source": [
    "## Test speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67d082c4-49b9-4a47-bafd-aaa784940307",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_distribution_pure = MurataBinned(pivot_mass, pivot_redshift)\n",
    "\n",
    "\n",
    "##### Parameters to be used in both recipes #####\n",
    "mass_points = 40\n",
    "redshift_points = 10\n",
    "log_proxy_points = 10\n",
    "sky_area = 440\n",
    "mass_interval = (12.0, 17.0)\n",
    "cluster_theory = cl_delta_sigma\n",
    "z_bin = (0.2, 0.4)\n",
    "z_points = np.linspace(z_bin[0], z_bin[1], redshift_points) \n",
    "proxy_bin = (1.0, 1.3)\n",
    "proxy_points = np.linspace(proxy_bin[0], proxy_bin[1], log_proxy_points)\n",
    "radius_center = 4.0\n",
    "average_on_counts = ClusterProperty.NONE\n",
    "average_on_shear = ClusterProperty.NONE\n",
    "average_on_shear |= ClusterProperty.DELTASIGMA\n",
    "#################################################\n",
    "\n",
    "recipe_integral_speed = MurataBinnedSpecZRecipe(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        #completeness=comp_dist,\n",
    "    )\n",
    "\n",
    "recipe_grid_speed = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cluster_theory,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        #completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    "    )\n",
    "recipe_grid_speed.reset_grids_cache()\n",
    "counts_grid = recipe_grid_speed.evaluate_theory_prediction_base(z_bin, proxy_bin, sky_area,average_on_counts)\n",
    "counts_integral = recipe_integral_speed.evaluate_theory_prediction_counts(z_bin, proxy_bin, sky_area, average_on_counts)\n",
    "\n",
    "counts_grid = recipe_grid_speed.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center,sky_area, average_on_shear)\n",
    "t2 = time.time()\n",
    "counts_integral = recipe_integral_speed.evaluate_theory_prediction_shear_profile(z_bin, proxy_bin, radius_center, sky_area,average_on_shear)\n",
    "t21 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51bab1ac-1e14-4b76-be56-6e98da5cd035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- One-shot counts ---\n",
      "Grid time:    0.0542 s\n",
      "Integral time: 0.0024 s\n",
      "\n",
      "--- One-shot shear ---\n",
      "Grid time:    0.2138 s\n",
      "Integral time: 0.5180 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Your parameters\n",
    "mass_distribution_pure = MurataBinned(pivot_mass, pivot_redshift)\n",
    "\n",
    "mass_points = 40\n",
    "redshift_points = 12\n",
    "log_proxy_points = 12\n",
    "sky_area = 440\n",
    "mass_interval = (12.0, 17.0)\n",
    "z_bin = (0.2, 0.4)\n",
    "proxy_bin = (1.0, 1.3)\n",
    "radius_center = 4.0\n",
    "\n",
    "average_on_counts = ClusterProperty.NONE\n",
    "average_on_shear  = ClusterProperty.DELTASIGMA\n",
    "\n",
    "# Recipes\n",
    "recipe_integral_speed = MurataBinnedSpecZRecipe(\n",
    "    mass_interval=mass_interval,\n",
    "    cluster_theory=cl_delta_sigma,\n",
    "    redshift_distribution=redshift_distribution,\n",
    "    mass_distribution=mass_distribution_pure,\n",
    "    #completeness=comp_dist,\n",
    ")\n",
    "\n",
    "recipe_grid_speed = MurataBinnedSpecZRecipeGrid(\n",
    "    mass_interval=mass_interval,\n",
    "    cluster_theory=cl_delta_sigma,\n",
    "    redshift_distribution=redshift_distribution,\n",
    "    mass_distribution=mass_distribution_pure,\n",
    "    #completeness=comp_dist,\n",
    "    log_proxy_points=log_proxy_points,\n",
    "    redshift_points=redshift_points,\n",
    "    log_mass_points=mass_points,\n",
    ")\n",
    "\n",
    "# ---- One-shot timing: counts ----\n",
    "recipe_grid_speed.reset_grids_cache()\n",
    "\n",
    "t0 = time.time()\n",
    "counts_grid = recipe_grid_speed.evaluate_theory_prediction_base(\n",
    "    z_bin, proxy_bin, sky_area, average_on_counts\n",
    ")\n",
    "t1 = time.time()\n",
    "\n",
    "counts_integral = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "    z_bin, proxy_bin, sky_area, average_on_counts\n",
    ")\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"\\n--- One-shot counts ---\")\n",
    "print(\"Grid time:    %.4f s\" % (t1 - t0))\n",
    "print(\"Integral time: %.4f s\" % (t2 - t1))\n",
    "\n",
    "\n",
    "# ---- One-shot timing: shear ----\n",
    "t0 = time.time()\n",
    "shear_grid = recipe_grid_speed.evaluate_theory_prediction_shear_profile(\n",
    "    z_bin, proxy_bin, radius_center, sky_area, average_on_shear\n",
    ")\n",
    "t1 = time.time()\n",
    "\n",
    "shear_integral = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "    z_bin, proxy_bin, radius_center, sky_area, average_on_shear\n",
    ")\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"\\n--- One-shot shear ---\")\n",
    "print(\"Grid time:    %.4f s\" % (t1 - t0))\n",
    "print(\"Integral time: %.4f s\" % (t2 - t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01bb54c3-0ea1-4376-a7df-aa336ff5344f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOTAL GRID TIME = 3.62 s\n",
      "TOTAL INTEGRAL TIME = 29.50 s\n",
      "\n",
      "--- RESULTS COMPARISON ---\n",
      "Total number of bins computed: 80\n",
      "RMS Relative Diff (Counts): 3.0806e-04\n",
      "RMS Relative Diff (Shear):  3.7307e-04\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "richness_bins = [(0.3,0.4), (0.4,0.6), (0.6,0.8), (0.8,1.0)]   # example\n",
    "proxy_bins    = [(1.0,1.1), (1.1,1.2), (1.2,1.3), (1.3,1.4), (1.4,1.5)]\n",
    "radii         = np.linspace(1.0, 10.0, 4)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Total GRID computation time\n",
    "# ----------------------------------------------\n",
    "recipe_grid_speed.reset_grids_cache()\n",
    "counts_grid_arr = []\n",
    "shear_grid_arr = []\n",
    "tg0 = time.time()\n",
    "for rbin in richness_bins:\n",
    "    for pbin in proxy_bins:\n",
    "        for R in radii:\n",
    "            counts_grid_arr.append(recipe_grid_speed.evaluate_theory_prediction_base(rbin, pbin, sky_area, average_on_counts))\n",
    "            shear_grid_arr.append(recipe_grid_speed.evaluate_theory_prediction_shear_profile(rbin, pbin, R, sky_area, average_on_shear))\n",
    "tg1 = time.time()\n",
    "print(\"\\nTOTAL GRID TIME = %.2f s\" % (tg1 - tg0))\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Total INTEGRAL computation time\n",
    "# ----------------------------------------------\n",
    "counts_int_arr = []\n",
    "shear_int_arr = []\n",
    "ti0 = time.time()\n",
    "for rbin in richness_bins:\n",
    "    for pbin in proxy_bins:\n",
    "        for R in radii:\n",
    "            counts_int_arr.append(recipe_integral_speed.evaluate_theory_prediction_counts(rbin, pbin, sky_area, average_on_counts))\n",
    "            shear_int_arr.append(recipe_integral_speed.evaluate_theory_prediction_shear_profile(rbin, pbin, R, sky_area, average_on_shear))\n",
    "ti1 = time.time()\n",
    "print(\"TOTAL INTEGRAL TIME = %.2f s\" % (ti1 - ti0))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Comparison of Results\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Convert lists to NumPy arrays for easy calculation\n",
    "counts_grid = np.array(counts_grid_arr)\n",
    "counts_int = np.array(counts_int_arr)\n",
    "shear_grid = np.array(shear_grid_arr)\n",
    "shear_int = np.array(shear_int_arr)\n",
    "\n",
    "counts_diff = np.where(\n",
    "    counts_int != 0.0, \n",
    "    np.abs(counts_grid - counts_int) / np.abs(counts_int), \n",
    "    0.0\n",
    ")\n",
    "rms_counts_diff = np.sqrt(np.mean(counts_diff**2))\n",
    "\n",
    "shear_diff = np.where(\n",
    "    shear_int != 0.0, \n",
    "    np.abs(shear_grid - shear_int) / np.abs(shear_int), \n",
    "    0.0\n",
    ")\n",
    "rms_shear_diff = np.sqrt(np.mean(shear_diff**2))\n",
    "\n",
    "# Final Comparison Printout\n",
    "print(\"\\n--- RESULTS COMPARISON ---\")\n",
    "print(\"Total number of bins computed: %d\" % len(counts_grid))\n",
    "print(\"RMS Relative Diff (Counts): %.4e\" % rms_counts_diff)\n",
    "print(\"RMS Relative Diff (Shear):  %.4e\" % rms_shear_diff)\n",
    "print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58905869-59a8-4f10-a321-9a4f6ffe87b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterProperty.DELTASIGMA\n"
     ]
    }
   ],
   "source": [
    "print(average_on_shear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80383885-0945-4e1c-bf2e-ed64072d9130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BEGIN ACCURACY SWEEP WITH COUNTS =====\n",
      "\n",
      "Test bin:\n",
      "  z = (0.200, 0.400)\n",
      "  proxy = (1.000, 1.300)\n",
      "  R = 4.000\n",
      "\n",
      "---- Sweep log_proxy_points ----\n",
      "\n",
      "Trying log_proxy_points = 2\n",
      "  shear diff  = 0.024303\n",
      "  counts diff = 0.148385\n",
      "\n",
      "Trying log_proxy_points = 5\n",
      "  shear diff  = 0.000034\n",
      "  counts diff = 0.000131\n",
      "  → Achieved ≤1% accuracy at log_proxy_points = 5\n",
      "\n",
      "---- Sweep redshift_points ----\n",
      "\n",
      "Trying redshift_points = 2\n",
      "  shear diff  = 0.030061\n",
      "  counts diff = 0.036235\n",
      "\n",
      "Trying redshift_points = 5\n",
      "  shear diff  = 0.000044\n",
      "  counts diff = 0.000093\n",
      "  → Achieved ≤1% accuracy at redshift_points = 5\n",
      "\n",
      "---- Sweep log_mass_points ----\n",
      "\n",
      "Trying log_mass_points = 5\n",
      "  shear diff  = 0.109240\n",
      "  counts diff = 0.261848\n",
      "\n",
      "Trying log_mass_points = 10\n",
      "  shear diff  = 0.225185\n",
      "  counts diff = 0.173935\n",
      "\n",
      "Trying log_mass_points = 20\n",
      "  shear diff  = 0.041281\n",
      "  counts diff = 0.003686\n",
      "\n",
      "Trying log_mass_points = 40\n",
      "  shear diff  = 0.000037\n",
      "  counts diff = 0.000082\n",
      "\n",
      "Trying log_mass_points = 60\n",
      "  shear diff  = 0.000007\n",
      "  counts diff = 0.000010\n",
      "\n",
      "Trying log_mass_points = 80\n",
      "  shear diff  = 0.000007\n",
      "  counts diff = 0.000010\n",
      "\n",
      "Trying log_mass_points = 120\n",
      "  shear diff  = 0.000007\n",
      "  counts diff = 0.000010\n",
      "\n",
      "===== END ACCURACY SWEEP WITH COUNTS =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def frac_diff(a, b):\n",
    "    return np.abs(a - b) / (np.abs(b) + 1e-12)\n",
    "\n",
    "\n",
    "print(\"\\n===== BEGIN ACCURACY SWEEP WITH COUNTS =====\\n\")\n",
    "\n",
    "# --- ranges to test ---\n",
    "proxy_sweep    = [2, 5, 10, 20, 30, 40, 60, 80, 120, 160]\n",
    "z_sweep        = [2, 5, 10, 20, 30, 40]\n",
    "mass_sweep     = [5, 10, 20, 40, 60, 80, 120]\n",
    "\n",
    "# --- fixed test bin ---\n",
    "z_lo, z_hi = z_bin\n",
    "proxy_lo, proxy_hi = proxy_bin\n",
    "R = radius_center\n",
    "\n",
    "print(\"Test bin:\")\n",
    "print(\"  z = (%.3f, %.3f)\" % z_bin)\n",
    "print(\"  proxy = (%.3f, %.3f)\" % proxy_bin)\n",
    "print(\"  R = %.3f\" % R)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1) PROXY SWEEP\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n---- Sweep log_proxy_points ----\")\n",
    "\n",
    "for pts in proxy_sweep:\n",
    "    print(f\"\\nTrying log_proxy_points = {pts}\")\n",
    "\n",
    "    recipe_grid_speed_pts = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_delta_sigma,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        #completeness=comp_dist,\n",
    "        log_proxy_points=pts,\n",
    "        redshift_points=redshift_points,\n",
    "        log_mass_points=mass_points,\n",
    "    )\n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    # Shear evaluation\n",
    "    val_shear = recipe_grid_speed_pts.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    \n",
    "    # Counts evaluation\n",
    "    counts_val = recipe_grid_speed_pts.evaluate_theory_prediction_base(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    # Reference shear\n",
    "    ref_shear = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    \n",
    "    # Reference counts\n",
    "    ref_counts = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    diff_shear  = float(frac_diff(val_shear, ref_shear))\n",
    "    diff_counts = float(frac_diff(counts_val, ref_counts))\n",
    "\n",
    "    print(\"  shear diff  = %.6f\" % diff_shear)\n",
    "    print(\"  counts diff = %.6f\" % diff_counts)\n",
    "\n",
    "    if diff_shear < 0.01 and diff_counts < 0.01:\n",
    "        print(\"  → Achieved ≤1% accuracy at log_proxy_points =\", pts)\n",
    "        break\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2) REDSHIFT SWEEP\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n---- Sweep redshift_points ----\")\n",
    "\n",
    "for pts in z_sweep:\n",
    "    print(f\"\\nTrying redshift_points = {pts}\")\n",
    "\n",
    "    recipe_grid_speed_pts = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_delta_sigma,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        #completeness=comp_dist,\n",
    "        log_proxy_points=log_proxy_points,\n",
    "        redshift_points=pts,\n",
    "        log_mass_points=mass_points,\n",
    "    )\n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    val_shear = recipe_grid_speed_pts.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    counts_val = recipe_grid_speed_pts.evaluate_theory_prediction_base(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "\n",
    "    ref_shear = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    ref_counts = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    diff_shear  = float(frac_diff(val_shear, ref_shear))\n",
    "    diff_counts = float(frac_diff(counts_val, ref_counts))\n",
    "    \n",
    "    print(\"  shear diff  = %.6f\" % diff_shear)\n",
    "    print(\"  counts diff = %.6f\" % diff_counts)\n",
    "\n",
    "    if diff_shear < 0.01 and diff_counts < 0.01:\n",
    "        print(\"  → Achieved ≤1% accuracy at redshift_points =\", pts)\n",
    "        break\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3) MASS SWEEP\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n---- Sweep log_mass_points ----\")\n",
    "\n",
    "for pts in mass_sweep:\n",
    "    print(f\"\\nTrying log_mass_points = {pts}\")\n",
    "\n",
    "    recipe_grid_speed_pts = MurataBinnedSpecZRecipeGrid(\n",
    "        mass_interval=mass_interval,\n",
    "        cluster_theory=cl_delta_sigma,\n",
    "        redshift_distribution=redshift_distribution,\n",
    "        mass_distribution=mass_distribution_pure,\n",
    "        #completeness=comp_dist,\n",
    "        log_proxy_points=log_proxy_points,\n",
    "        redshift_points=redshift_points,\n",
    "        log_mass_points=pts,\n",
    "    )\n",
    "    recipe_grid_speed_pts.reset_grids_cache()\n",
    "    \n",
    "    val_shear = recipe_grid_speed_pts.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    counts_val = recipe_grid_speed_pts.evaluate_theory_prediction_base(\n",
    "        z_bin, proxy_bin,  sky_area\n",
    "    )\n",
    "\n",
    "    ref_shear = recipe_integral_speed.evaluate_theory_prediction_shear_profile(\n",
    "        z_bin, proxy_bin, R, sky_area, average_on_shear\n",
    "    )\n",
    "    ref_counts = recipe_integral_speed.evaluate_theory_prediction_counts(\n",
    "        z_bin, proxy_bin, sky_area\n",
    "    )\n",
    "    \n",
    "    diff_shear  = float(frac_diff(val_shear, ref_shear))\n",
    "    diff_counts = float(frac_diff(counts_val, ref_counts))\n",
    "    \n",
    "    print(\"  shear diff  = %.6f\" % diff_shear)\n",
    "    print(\"  counts diff = %.6f\" % diff_counts)\n",
    "\n",
    "    # Optional early break if both ≤1%\n",
    "    # if diff_shear < 0.01 and diff_counts < 0.01:\n",
    "    #     print(\"  → Achieved ≤1% accuracy at log_mass_points =\", pts)\n",
    "    #     break\n",
    "\n",
    "\n",
    "print(\"\\n===== END ACCURACY SWEEP WITH COUNTS =====\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244aaf96-29eb-476c-b821-e06bccc2a954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.    3.25  5.5   7.75 10.  ]\n"
     ]
    }
   ],
   "source": [
    "print(np.linspace(1,10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac3e65-7df4-416b-bd47-1c7cdd6b49b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (firecrown20.0)",
   "language": "python",
   "name": "firecrown_20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
